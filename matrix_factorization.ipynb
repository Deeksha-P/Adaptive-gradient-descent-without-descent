{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix factorization\n",
    "\n",
    "We want to minimize\n",
    "$$\\min_X f(X)=f(U,V):=\\frac 1 2 \\|U V^\\top - A\\|^2_F,$$\n",
    "where  $A\\in {\\mathbb R}^{m\\times n}$, $U\\in {\\mathbb R}^{m\\times r}$, $V\\in {\\mathbb R}^{n\\times r}$ and $r<\\min\\{m,n\\}$.\n",
    "The gradient is given by $\\nabla f(X) = [(UV^\\top -A) V^\\top, (UV^\\top-A)^\\top U]^\\top$.\n",
    "\n",
    "This is a nonconvex problem, moreover due to the product $UV^\\top$, the gradient $\\nabla f$ is not globally Lipschitz (but locally is).\n",
    "\n",
    "For this experiment we used [Movielens 100K dataset](https://grouplens.org/datasets/movielens/100k/). In particular, we used the file `u.data` from that archive.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg as LA\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from algorithms import *\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the dataset and write all data to the sparse matrix $A$. This matrix will collect movie ratings from $943$ users on $1682$ movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from disk\n",
    "names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df = pd.read_csv('datasets/u.data', sep='\\t', names=names)\n",
    "n_users = df.user_id.unique().shape[0]\n",
    "n_items = df.item_id.unique().shape[0]\n",
    "\n",
    "# Create r_{ui}, our ratings matrix\n",
    "ratings = np.zeros((n_users, n_items))\n",
    "for row in df.itertuples():\n",
    "    ratings[row[1]-1, row[2]-1] = row[3]\n",
    "\n",
    "A = ratings\n",
    "m, n = A.shape\n",
    "print(\"The dimensions of A are:\", m, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the value for r (10, 20, 30)\n",
    "\n",
    "r = 20\n",
    "\n",
    "def f(X):\n",
    "    U, V = X[:m], X[m:]\n",
    "    return 0.5* LA.norm(U @ V.T - A)**2\n",
    "\n",
    "def df(X):\n",
    "    U, V = X[:m], X[m:]\n",
    "    res = U @ V.T - A\n",
    "    grad_U = res @ V\n",
    "    grad_V = res.T @ U\n",
    "    return np.vstack([grad_U, grad_V])\n",
    "\n",
    "\n",
    "# evaluation function.\n",
    "J = lambda x: LA.norm(x)\n",
    "\n",
    "# the starting point \n",
    "np.random.seed(0)\n",
    "X0 = np.random.randn(m + n, r)\n",
    "\n",
    "# number of iterations\n",
    "N = 30000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that in order to run GD or AGD, we require manually to tune a stepsize $1/L$. We found it by many rounds of trial and errors. Interestingly, both these methods converge with different steps, and they both diverge if one takes in two times larger steps respectively.\n",
    "\n",
    "\n",
    "Here is the values of $L$, for which GD and Nesterov GD work well and they don't work if we decrease $L$ in $2$ times\n",
    "\n",
    "| r  |      GD      |  Nesterov |\n",
    "|----|:------------:|------:|\n",
    "| 10 |  1000 |10000   |\n",
    "| 20 |  1000    |30000   |\n",
    "| 30 | 1000|  20000   |\n",
    "\n",
    "Yes, it is very strange. For symmetry, it would be much better if we swap last two values in the third column.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient descent\n",
    "L = 1000\n",
    "ans1 = gd(J, df, X0, 1./L, numb_iter=N)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that it doesn't work with L=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# checking that smaller step will not work for GD\n",
    "# you can skip it\n",
    "N_ = 1000\n",
    "L = 500\n",
    "try:\n",
    "    ans1_not = gd(J, df, X0, 1./L, numb_iter=N_)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nesterov accelerated gradient descent\n",
    "L = 30000\n",
    "ans2 = accel_gd(J, df, X0, 1./L, numb_iter=N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking that smaller step will not work for acceleretaed GD\n",
    "# you can skip it\n",
    "N_ = 10000\n",
    "L = 15000\n",
    "try:\n",
    "    ans2_not = accel_gd(J, df, X0, 1./L, numb_iter=N_)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adaptive GD\n",
    "ans3 = ad_grad(J, df, X0, 1e-9, numb_iter=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adaptive acelerated GD (heuristic)\n",
    "ans4 = ad_grad_accel(J, df, X0, 1e-9, numb_iter=N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\", context=\"talk\", font_scale=1.2, palette=sns.color_palette(\"bright\"), color_codes=False)\n",
    "\n",
    "answers = [ans1, ans2, ans3, ans4]\n",
    "values = [ans[0] for ans in answers]\n",
    "labels = [\"GD\", \"Nesterov\", \"AdGD\", \"AdGD-accel\"]\n",
    "markers = [',', 'o', '*',  'D']\n",
    "\n",
    "n_plot = 400\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, val in enumerate(values):\n",
    "    skip = len(val) // n_plot\n",
    "    plt.plot(\n",
    "        np.arange(0, len(val), skip), \n",
    "        val[::skip], label=labels[i],\n",
    "        marker=markers[i], markevery=20)\n",
    "    \n",
    "plt.yscale('log')\n",
    "plt.xlabel(u'Iteration')\n",
    "plt.ylabel(r'$\\Vert \\nabla f(x^k)\\Vert$')\n",
    "plt.legend()\n",
    "#plt.savefig('../plots/for_paper/factorization={}.pdf'.format(r), bbox_inches='tight', dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save all data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('saved_data/factorization-{}.npy'.format(r), np.vstack([ans[0] for ans in answers]))  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
